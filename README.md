# IMLLA-FinalProject
Repository for the final project for Introduction for Machine Learning for Linguistics Applications.

## Project proposal

Full description of the project is available on Google Docs: https://docs.google.com/document/d/1cfPv_zhlnV8oHgj630l0FwApVC4BhZqme6AO02B6pac

## Workflow documentation

1. Joint work: creation of reference tables with job titles (reference dictionary: resources)
2. Monika worked on type 1 examples from NKJP using tokenization – most of type 1 examples were annotated by her (referenece directory: examples_monika)
3. Ariel worked on some type 1 examples from NKJP using regexes and added type 0 examples: some of them were found in NKJP while cleaning type 1 examples, the rest was added from Wikipedia using scraper from week 7 homework and by copying and pasting short novels from [WolneLektury.pl](https://wolnelektury.pl/) into a txt file (referenece directories: raw_examples_ariel, cleaned_examples_ariel)
4. After making sure the examples are properly coded (no job titles in type 0 examples!) and the proportions are correct, Ariel compiled the data into one dataset and pushed it to Hugging Face (reference directory: dataset, referenece repository: [ArielUW/jobtitles](https://huggingface.co/datasets/ArielUW/jobtitles))
5. Monika trained the network and pushed it to Hugging Face (reference directory: training, reference repository: [mongrz/neutral_job_title_rephraser_pl](https://huggingface.co/mongrz/neutral_job_title_rephraser_pl))
6. Monika deployed the model on the test split and calculated binary evaluation metrics, i.e.: Attempted noun neutralisation precision and Attempted noun neutralisation recall (reference directory: outputs and evaluation).
7. Ariel prepared the evaluation of metrics based on Levenstein's distance (reference directory: outputs and evaluation).
8. Alongside other work, Ariel prepared the dataset's readme file and this readme, which was supplemented by Monika near the end, when she had obtained results of the evaluation.
9. Ariel and Monika filled in addtional details in the model card on Hugging Face.

## Evaluation of the model

### Metrics:
– Attempted noun neutralisation precision: [1]
– Attempted noun neutralisation recall: [0.892]
Both values are above the assumed threshold value (0.5).

– Normalized Levensthein's distance for type 1: [0.0395]
– Normalized Levensthein's distance for type 0: [0.0001]
Both values are below the assumed maximum threshold value (0.04 and 0.02).
Note: instead of using [edit_distance()] from NLTK library, [distance()] from Levenshtein library was used.

* Only one out of 250 (0%) type 0 targets was different from the correct anwser. 
Additionally, it was revealed that the mistake was caused by the appearance of a semantic edge case in type 0 subset, which should not be the case:
_Target in the test set:_ Oprócz wątka sakralnego, który towarzyszyć będzie *autorowi* przez całe życie, szczególnie bliskiego wielu tym, którzy, jak Paszkiewicz, w bardzo młodym wieku zetknęli się z tragedią obozów koncentracyjnych, upodleniem, rozpaczą, gwałtowną śmiercią lub jej przeciwieństwem - powolnym umieraniem z głodu i wycieńczenia, ujawnia się tu głęboko humanistyczny i humanitarny zarazem krzyk w obronie ""ginących w nicość i samotność"", próba uratowania ich od ostatecznego unicestwienia.
_Target generated by the model:_ Oprócz wątka sakralnego, który towarzyszyć będzie *osobie autorskiej* przez całe życie, szczególnie bliskiej wielu tym, którzy, jak Paszkiewicz, w bardzo młodym wieku zetknęli się z tragedią obozów koncentracyjnych, upodleniem, rozpaczą, gwałtowną śmiercią lub jej przeciwieństwem - powolnym umieraniem z głodu i wycieńczenia, ujawnia się tu głęboko humanistyczny i humanitarny zarazem krzyk w obronie ""ginących w nicość i samotność"", próba uratowania ich od ostatecznego unicestwienia.
Given that it is unclear whether *autor* should be treated as a profession or not, this example should not have made it to the test set (or should have been treated as a type 1 example). It can, however, be observed that the generated output is in line with our expectations for type 1 sentences.

* 133 out of 250 (53%) type 1 targets were non-identical to the gold-standard counterparts.
However, many of the non-identical tagets still contained valid attempts and neutralisation (as evidenced by high precision and the qualitative analysis). Oftentimes the differences were minor (as evidenced by low mean standardized Levensthein distances) and/or beyond the scope of the main interest of the study (as evidenced by high precision), or even fully attributable to mistakes in the dataset (as laid out in the qualitative analysis).

* The perfect precision value (100%) is explained by the fact that our model did not attempt to rephrase type 0 sentences (i.e., the ones that did not contain human-related or job-related terms). It might also be explained by the relatively low diversity of the dataset – with more varied inputs, it remains to be seen if it would continue performing perfectly. 

* The very high recall value (89.2%) means that the model performed well in terms of identifying the items requiring change. However, this measure does not take into account whether the solution was well done – just that an attempt was made. It can be hypothesised that the model performed best with higher-frequency job titles and more regular adjectives (i.e. the terms where the personative adjective is a common adjective describing the profession, e.g. żołnierz > osoba żołnierska). However, with previously unseen or rare items, it typically identified the spot where changes were needed, but it was not always successful at coming up with a plausible solution. It is likely that performance could be improved with a larger and more varied dataset, with a larger representation of diverse low-frequency job titles, and also a larger representation of feminine job titles, as these tended to be the 'no attempt made' rows.

### Qualitative analysis of errors in type 1 examples

Examples are presentend in the following order: *target prepared by annotators* ▶️ *generated target*

1. There were some valid attempts at neutralising a job title that lead to incorrect results:
– parlamentarzysta: *_Osoba parlamentarzystyczna_ nie chce uczestniczyć w kluczowej dla współczesnej Europy debacie: jak budować poczucie obywatelskiej wspólnoty i wzajemnego zaufania w wielokulturowym świecie.* ▶️ *_Osoba parlamentarska_ nie chce uczestniczyć w kluczowej dla współczesnej Europy debacie: jak budować poczucie obywatelskiej wspólnoty i wzajemnego zaufania w wielokulturowym świecie.*
– psychiatra: *U młodej dziewczyny _osoba zajmująca się psychiatrią_ rozpoznała początki choroby psychicznej, dziewczyna myśli o samobójstwie.* ▶️ *U młodej dziewczyny _osoba psychiaterska_ rozpoznała początki choroby psychicznej, dziewczyna myśli o samobójstwie.*
– narrator: *Ten, kto dyktuje warunki, kto powołał _osobę narratorską_ i kto tak długo zostawiał bez odpowiedzi listy i faksy, przypomina sobie co jakiś czas o zaległych sprawach, poczynając od cieknącego kranu, a kończąc na bankowych dyspozycjach.* ▶️ *Osoba, która dyktuje warunki, kto powołał _osobę narraterską_ i kto tak długo zostawiał bez odpowiedzi listy i faksy, przypomina sobie co jakiś czas o zaległych sprawach, poczynając od cieknącego kranu, a kończąc na bankowych dyspozycjach.*
– operator: *Grochulski - wskazał rudego - też robi za siebie i _osobę operatorską_ radaru.,Grochulski - wskazał rudego - też robi za siebie i _osoby operaterskiej_ radaru.*
– pilot: *Załogę samolotu stanowią dwie _osoby pilockie_ i osoba inżynierska pokładowa oraz sześć osób obsługi pokładowej.* ▶️ *Załogę samolotu stanowi dwie _osoby pilotackie_ i inżynierskie pokładowe oraz sześć osób obsługi pokładowej.*
– wicepremier: *_Osoba wicepremierska_ Roman Malinowski pyta o rozmiary sił i środków niezbędnych dla przeprowadzenia tej akcji i czy możliwe będzie zbudowanie tych przegród na Wiśle do 15 bm.* ▶️ *_Osoba wicepremerska_ Roman Malinowski pyta o rozmiary sił i środków niezbędnych dla przeprowadzenia tej akcji i czy możliwe będzie zbudowanie tych przegród na Wiśle do 15 bm.*

2. In other cases, job titles were left completely unchanged:
– kopista (rare job title): *Baszmaczkina sam niegdyś postawiłem w dzienniku obok osoby kopistycznej Bartleby z noweli Melville'a.* ▶️ *Baszmaczkina sam niegdyś postawiłem w dzienniku obok kopisty Bartleby z noweli Melville'a.*
– mistrzyni (feminine noun in source): *Oprócz rekordu, _Osoba Mistrzowska_ zaprezentowała swoją siłę także na inne sposoby – unosząc samochód oraz podnosząc nad głowę ponad 80-kilogramowego mężczyznę.* ▶️ *Oprócz rekordu, _Mistrzyni_ zaprezentowała swoją siłę także na inne sposoby – unosząc samochód oraz podnosząc nad głowę ponad 80-kilogramowego mężczyznę.*
– sprzątaczka (feminine noun in source): *Sięgnął po słuchawkę, wybrał numer wewnętrzny sekretariatu, ale odezwała się tylko _osoba sprzątająca_.* ▶️ *Sięgnął po słuchawkę, wybrał numer wewnętrzny sekretariatu, ale odezwała się tylko _sprzątaczka_.*
– rówieśnik (semantic edge case that probably shouldn't be included): *Ja sam w szkole chodziłem w czapce w kamuflarz z doszytym futerkiem ""na irokeza"" i budziłem niezdrowe emocje w _osobach rówieśniczych_.* ▶️ *Ja sam w szkole chodziłem w czapce w kamuflarz z doszytym futerkiem ""na irokeza"" i budziłem niezdrowe emocje w _rówieśnikach_.*
– politycy, żurnaliści (multiple changes in one sentence + a rare job title): *Wiadomość z Langley oznacza, że osoba generalska Jaruzelski wprowadzając stan wojenny ocaliła 200 tysięcy ludzi, ale zaślepione osoby hunwejbińskie z IPN oraz prawicowe _osoby polityckie_ i _żurnalistyczne_ uważają inaczej.* ▶️ *Wiadomość z Langley oznacza, że osoba generalska Jaruzelski wprowadzając stan wojenny ocaliła 200 tysięcy ludzi, ale zaślepieni hunwejbini z IPN oraz prawicowi _politycy_ i _żurnaliści_ uważają inaczej.*
– mleczarz: *W 2000 roku sejneńskie _osoby mleczarskie_ skupiły ponad 23 mln litrów surowca.* ▶️ *W 2000 roku sejneńscy _mleczarze_ skupili ponad 23 mln litrów surowca.*
– ślusarz: *Prosty chłopak, z zawodu _osoba ślusarska_, a proszę, do czego doszedł: dwa domy, kilka samochodów, duże pieniądze.* ▶️ *Prosty chłopak, z zawodu _ślusarz_, a proszę, do czego doszedł: dwa domy, kilka samochodów, duże pieniądze.*
– poseł (multiple changes in one sentence): *_Osoba poselska_ od 1997 r. Andrzej Markowiak - 54 l., osoba inżynierska mechanicza.","_Poseł_ od 1997 r. Andrzej Markowiak - 54 l., osoba inżynierska mechaniczna.*
– cukiernik: *Jako ceniona _osoba cukiernicza_ trafił od razu do jednego z pięciogwiazdkowych hoteli w stolicy kraju, Seulu.* ▶️ *Jako ceniony _cukiernik_ trafił od razu do jednego z pięciogwiazdkowych hoteli w stolicy kraju, Seulu.*

3. A lot of model's mistakes were related to case agreement and other morphosyntactical aspects that were deemed beyond the scope of the project, but had to be included in the target sentences nevertheless, e.g.:
– subject-verb agreement: *Do pracy naukowej _wróciła_ również niedawna osoba liderska UP, RYSZARD BUGAJ.* ▶️ *Do pracy naukowej _wrócił_ również niedawna osoba liderska UP, RYSZARD BUGAJ.* (prevalent group of morphosyntactic errors, additional examples: 5)
– object-verb agreement: *Na razie jedynie weto Kwaśniewskiego może powstrzymać _pazerne osoby awuesiarskie_, którzy mnożąc urzędy rozbudowują dla siebie przechowalnię.* ▶️ *Na razie jedynie weto Kwaśniewskiego może powstrzymać _pazernych osób awuesiarskich_, którzy mnożąc urzędy rozbudowują dla siebie przechowalnię.*
– attribute-noun agreement: *– bo on chyba _jakąś_ osobą dyrektorską przecież został nie?* ▶️ *– bo on chyba _jakimś_ osobą dyrektorską przecież został nie?*
– word order: *Ta wizja macierzyństwa spotkała się z polemiką ze strony _pacyfistycznej i feministycznej osoby działaczej_ Madeleine Vernet (1878-1949).* ▶️ *Ta wizja macierzyństwa spotkała się z polemiką ze strony _osoby działaczej pacyfistycznej i feministycznej_ Madeleine Vernet (1878-1949).*
– some issues related to numerals (most likely: different behaviour of masculine vs. feminine nouns for cardinal numeral 2-4 in nominative case, but also possibly: morphosyntactic differences between cardinal numerals expressing the value of 2-4 and >4 ): *_Cztery młode osoby żołnierskie_ w granatowych mundurach MSW mocno _zapukały_ do drzwi.* ▶️ *_Czterech młodych osób żołnierskich_ w granatowych mundurach MSW mocno _zapukało_ do drzwi.*
– issues related to more complex isuess with abstract reasoning, such as the total number of people in the sentence: *Załogę samolotu stanowią _dwie osoby pilockie i osoba inżynierska pokładowa_ oraz sześć osób obsługi pokładowej.* ▶️ *Załogę samolotu stanowi dwie _osoby pilotackie i inżynierskie pokładowe_ oraz sześć osób obsługi pokładowej.*

4. Some changes were made in fact correctly, but they were beyond the scope of what was expected from the model, or the model invented a different valid form than the one provided in the set:
– czytelnik (correct form, but with object-verb agreement error): *Rozwiązując swoją drugą zagadkę kryminalną, młoda osoba detektywistyczna po raz kolejny zabiera _młodych czytelników_ w pasjonującą podróż po barwnym świecie opactwa benedyktyńskiego* ▶️ *Rozwiązując swoją drugą zagadkę kryminalną, młoda osoba detektywistyczna po raz kolejny zabiera _młodych osób czytelniczych_ w pasjonującą podróż po barwnym świecie opactwa benedyktyńskiego"*
– pielgrzymi (correct alternative version): *Za chwilę zgłosiła się ta sama osoba pracująca w recepcji i bez wstępów, widocznie konsultowała rzecz z siostrą, powiedziała: - Łączę z działem obsługi _osób pielgrzymujących_.* ▶️ *Za chwilę zgłosiła się ta sama osoba pracująca w recepcji i bez wstępów, widocznie konsultowała rzecz z siostrą, powiedziała: - Łączę z działem obsługi _osób pielgrzymskich_.*
– szef (correct alternative version): *Informację tygodnika ""Capital"", iż komisja śledcza Bundestagu ds. afery finansowej CDU zbada zarzuty przeciwko Siemensowi i b. osobie kanclerskiej, potwierdziła wczoraj _osoba szefująca_ komisji Volker Neumann.* ▶️ *Informację tygodnika ""Capital"", iż komisja śledcza Bundestagu ds. afery finansowej CDU zbada zarzuty przeciwko Siemensowi i b. osobie kanclerskiej, potwierdziła wczoraj _osoba szefowska_ komisji Volker Neumann.*
– fotograf (model's solution is not a perfect solution, but acceptable): *Pewnego dnia _osoba zajmująca się fotografią_ odkryje prawdę i będzie musiała zdecydować: czy kocha miłą powierzchowność Noelle czy fascynującą osobowość, ale i niezbyt kształtną figurę Abby.* ▶️ *Pewnego dnia _osoba fotografska_ odkryje prawdę i będzie musiał zdecydować: czy kocha miłą powierzchowność Noelle czy fascynującą osobowość, ale i niezbyt kształtną figurę Abby.*

5. Other differences are related to technical mistakes in the dataset:
– missing annotation of the second job title (the model's solution is better than the 'gold standard'): *Ponownie zabrakło punktów osoby juniorskiej - powiedział _opiekun Płomienia_, Franciszek Hylla.* ▶️ *Ponownie zabrakło punktów osoby juniorskiej - powiedziała _osoba opiekująca się Płomienia_, Franciszek Hylla.*
– missing annotation of the second job title (the model's solution is better than the 'gold standard'): *Straciła zezwolenie i została oskarżona. 72-letnia osoba farmaceucka sprzedawała więcej niż jej _pracownicy_.* ▶️ *Straciła zezwolenie i została oskarżona. 72-letnia osoba farmaceucka sprzedawała więcej niż jej _osoby pracownicze_.*
– grammaticar error of the annotator (the model's solution is still not correct, but the 'gold standard' is also wrong): *Osoby lekarskie i pielęgniarskie o oczach czerwonych od niewyspania _słaniali_ się na nogach ze zmęczenia, samoloty dowoziły szczepionkę z różnych końców świata: epidemia była przecież wtedy zaskoczeniem.* ▶️ *Osoby lekarskie i pielęgniarskie o oczach czerwonych od niewyspania _słaniły_ się na nogach ze zmęczenia, samoloty dowoziły szczepionkę z różnych końców świata: epidemia przecież była wtedy zaskoczeniem.*
– grammaticar error of the annotator (the model's solution is better than the 'gold standard'): *W takiej sytuacji decyzję podejmuje sama osoba podatnicza, _który_ samodzielnie wypełnia roczne zeznanie podatkowe i nie musi przy tym pytać osób urzędniczych o zdanie.* ▶️ *W takiej sytuacji decyzję podejmuje sama osoba podatnicza, _która_ samodzielnie wypełnia roczne zeznanie podatkowe i nie musi przy tym pytać osób urzędniczych o zdanie.*
– grammaticar error of the annotator (the model's solution is better than the 'gold standard'. Moreover, there is a capitalization inconsistency that has not been discussed by the annotators and has lead to unexpected variability): *Osoba naczelnicza ulicznych osób rzeźniczych _wykrzywił_ twarz.* ▶️ *Osoba Naczelnicza ulicznych osób rzeźniczych _wykrzywiła_ twarz.*
– spelling error of the annotator (the model's solution is better than the 'gold standard'): *Jaka jest pewność, że Pismo Święte po wielu tłumaczeniach oddaje wiernie to, co osoby autorskie _mialy_ na myśli...* ▶️ *Jaka jest pewność, że Pismo Święte po wielu tłumaczeniach oddaje wiernie to, co osoby autorskie _miały_ na myśli...*
– trailing white space: *Osoba logopedzka diagnozuje i leczy wady wymowy u dzieci i dorosłych. * ▶️ *Osoba logopedzka diagnozuje i leczy wady wymowy u dzieci i dorosłych.*
– non-breaking whitespace after one-letter words (present due to conventions on trailing short words at the end of a line in printed text; removed by the model): *Kto z państwa osób senatorskich jest za przyjęciem poprawek: dwudziestej trzeciej, dwudziestej szóstej, trzydziestej szóstej i czterdziestej, proszę o naciśnięcie przycisku ""za"".* ▶️ *Kto z państwa osób senatorskich jest za przyjęciem poprawek: dwudziestej trzeciej, dwudziestej szóstej, trzydziestej szóstej i czterdziestej, proszę o naciśnięcie przycisku ""za"".*

6. The most exceptional change is a completely unexpected application of the rule to a gendered pronoun (this is outside the scope of the current project, but is a welcome addition; it also bodes well in terms of expanding the scope of the project that the model has already picked up on the gendered character of this word):
"_Ten, kto dyktuje warunki_, kto powołał osobę narratorską i kto tak długo zostawiał bez odpowiedzi listy i faksy, przypomina sobie co jakiś czas o zaległych sprawach, poczynając od cieknącego kranu, a kończąc na bankowych dyspozycjach."
"_Osoba, która dyktuje warunki_, kto powołał osobę narraterską i kto tak długo zostawiał bez odpowiedzi listy i faksy, przypomina sobie co jakiś czas o zaległych sprawach, poczynając od cieknącego kranu, a kończąc na bankowych dyspozycjach."

## Errors and shortcomings

1. Despite our best efforts, there were mistakes in the dataset: the reason for that is the fact that we didn't have enough resources to provide any proofreading. Standard practice would be to have at least two annotators and one superannnotator – in our case, every example was prepared by one annotator without proofreading. Additionally, even though some normalization has been performed at different stages for different subsets of the data, it wasn't consistent enough to ensure adequate conditions for fully reliable metrics based on Levensthein's distance.
– On one hand, errors present in the training/validation splits may have contributed to worse-than-possible training results (model could come to "wrong conclusions" based on erroneous examples in training),
– On the other hand, errors present in the test split have likely caused the output quality to be worse than it could have been (there are several cases where model was "more correct" than the test data 'gold standard' target; at the same time it is very unlikely for the annotators to commit an error that is *exactly* the same as an error later generated by the model for *exactly* the same test example),
– However, the number of errors is not too big and can  easily be remedied by having even one round of proofreading. Proofreading has not been performed before submitting this project, as at this stage it would equate to falsifying documentation. However, it is clear that better data quality would lead to much better results, and proofreading is a very important element of quality assurance.

2. The dataset was not balanced the way it was intended to be (in terms of morphological variety of job titles), nor was it as homogenous as intended (there were semantic edge cases present, as well as a variety of cases instead of just singular nominative forms), and some of the examples contained more than one job title.
– This has made the task all the more complicated for the model, as there are more parameters influencing the quality of the output, such as possible mistakes concerning case endings, number agreement, recognizing edge cases etc.

## Conclusions

The results are very promising and much better than expected. The relatively high quality of the obtained outputs is especially surprising given the errors present in the dataset. Despite it not being the goal, the model made valid attempts at neutralizing edge cases (_osoby czytelnicze_) and provided partially correct gramatical adjustments.

It is advisable to proofread the existing dataset [ArielUW/jobtitles], as well as to expand it with additional examples tailored to adress:
– the most problematic morphological types of job titles (such as the ones neutralised to: _osoba zajmująca się (...)_),
– feminine nouns,
– higher representation of low-frequency items, especially in high-frequency morphosyntactic types, to ensure generalization
– morphosyntactic intricacies of subject-verb agreement, case and number agreement and co-reference,
– multiple changes per one sentence.

Finally, the texts in the dataset need to be properly normalised, especially in the test split, to ensure uniformity in terms of:
– dashes (en vs em),
– hyphens (breaking vs non-breaking ones),
– ellipses (three dots vs single elpisis character),
– whitespaces (standard vs non-breaking space),
– quotation marks,
– no trailing whitespaces.

It is worth considering if more than one correct version (if it exist for a particular sentence) should be provided in the test split for a more accurate evaluation. With this conditional approach, the higher Levenshtein distance value would be selected 

After that the training process should be repeated from scratch for the base model, as the here presented fine-tuned model was most likely negatively affected by the existence of errors in the dataset.

Furthermore, the project is worth expanding more generally. Here are some possible vectors of further development, in terms of data worth collecting and training on:
– both shorter and longer inputs (e.g. just the job titles to neutralize instead of sentences, but also multi-sentence texts),
– representation of person-naming nouns that are not specifically job titles (e.g. *sąsiadka, zwolenniczka, hobbysta, posiadacz, znajoma* etc.)
– items that are already using gender-neutral personatives, so no changes are needed,
– items that are using a different gender-neutral strategy (e.g. *pracownik_czka*) that should be changed to personatives, so that texts maintain internal consistency,
– a conditional logic for only neutralizing nouns related to persons who are non-binary or undefined in terms of gender, while gendering the other people in texts as they wish to be gendered (probably the most ambitious, but also the most desirable for real-life use cases).
